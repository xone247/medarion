# Quick Fix Commands for Vast.ai (Copy-paste into Jupyter Terminal)

# ============================================================
# STEP 1: Check if API is running
# ============================================================
ps aux | grep "python3.*run_api_on_vast.py" | grep -v grep

# If you see output, API is running. If not, go to STEP 2.

# ============================================================
# STEP 2: Check model files
# ============================================================
ls -lh /workspace/model_api/extracted/ | head -10

# Should show tokenizer.json, config.json, and model files

# ============================================================
# STEP 3: Kill old API process (if needed)
# ============================================================
pkill -f "python3.*run_api_on_vast.py"

# ============================================================
# STEP 4: Start API
# ============================================================
cd /workspace
nohup python3 run_api_on_vast.py > api.log 2>&1 &

# Wait 30 seconds for model to load
sleep 30

# ============================================================
# STEP 5: Check if API started
# ============================================================
ps aux | grep "python3.*run_api_on_vast.py" | grep -v grep

# ============================================================
# STEP 6: Check API logs
# ============================================================
tail -50 api.log

# Look for:
# ✅ "Model loaded successfully!"
# ✅ "Running on all addresses (0.0.0.0)"
# ❌ Any errors

# ============================================================
# STEP 7: Test health endpoint
# ============================================================
curl -H "X-API-Key: medarion-secure-key-2025" http://localhost:5000/health

# Should return: {"status":"ok","model":"Medarion-Mistral-7B"}

# ============================================================
# STEP 8: Test chat endpoint
# ============================================================
curl -X POST \
  -H "Content-Type: application/json" \
  -H "X-API-Key: medarion-secure-key-2025" \
  -d '{"messages":[{"role":"user","content":"Hello, who are you?"}]}' \
  http://localhost:5000/chat

# Should return JSON with "choices" array

# ============================================================
# STEP 9: Check port 5000
# ============================================================
lsof -i :5000

# Should show python3 process listening on port 5000

# ============================================================
# TROUBLESHOOTING
# ============================================================

# If port 5000 is already in use:
fuser -k 5000/tcp
# Then restart API (STEP 4)

# If model files are missing:
# The script should auto-download from S3
# Check: ls -lh /workspace/model_api/extracted/

# If API won't start:
# Check logs: tail -100 api.log
# Check Python: python3 --version
# Check GPU: nvidia-smi

